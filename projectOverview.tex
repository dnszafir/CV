Machine learning algorithms transform large collections of data into classifications and predictions that can be used to guide decision making. The computations underlying these algorithms are complex and often difficult for humans to interpret. This complexity may hinder analysts' abilities to effectively refine and apply machine learning algorithms in practice. To address these limitations, we propose a visualization approach that reduces cognitive barriers to using machine learning by allowing users to analyze how different dimensions of a dataset contribute to on-going classifications and how computations evolve over the course of an algorithm's execution.

This project consists of three discrete phases. In the first, we will build on the PI's prior work in visual aggregation to design and empirically evaluate a series of prototype interfaces for visualizing how features are combined to generate classifications. The second phase will explore how   

Basic idea: ML visualizations focus on outputs. How can we make the process: the uncertainties and rationales behind the classifications, transparent for lay users? If we can do this, we can actually create supervisory systems for humans and machines to cooperatively engage in data processing, speeding up time to convergence and improving the interpretation of machine-processed data. 

